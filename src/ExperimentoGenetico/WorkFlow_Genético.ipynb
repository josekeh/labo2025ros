{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "859d38e7-11c0-48bc-978a-d0e907f19ed1",
      "metadata": {
        "id": "859d38e7-11c0-48bc-978a-d0e907f19ed1"
      },
      "source": [
        "# 8 WorkFlow  Semillerio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c586e3-ed7d-44b2-92a0-f19669f06940",
      "metadata": {
        "id": "29c586e3-ed7d-44b2-92a0-f19669f06940"
      },
      "source": [
        "### 8.1 Objetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fff8327-10ed-4b11-bbee-f1c3f357d123",
      "metadata": {
        "id": "6fff8327-10ed-4b11-bbee-f1c3f357d123"
      },
      "source": [
        "Presentar un workflow/pipeline completo al que los estudiantes deberán enriquecer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PX0qg_c0yqob",
      "metadata": {
        "id": "PX0qg_c0yqob"
      },
      "source": [
        "#### 8.2  Seteo del ambiente en Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NGY7H9xza7Zr",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7PupIBNba7Zr",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9LpZCst5a7Zs",
      "metadata": {
        "id": "9LpZCst5a7Zs",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JYC_F-wla7Zs",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "*   Bajar el **dataset_historico** al Google Drive y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fcqHsG9hdlx",
      "metadata": {
        "id": "4fcqHsG9hdlx"
      },
      "source": [
        "*  Si usted eligió modalidad *Gerencial* entonces NO debe modificar nada, su liderazgo logró que otras trabajaron por usted\n",
        "*  Si usted eligió modalidad de *Analista Junior*, entonces donde dice archivo=\"gerencial_competencia_2025.csv.gz\"  lo debe cambiar por  archivo=\"analistajr_competencia_2025.csv.gz\"\n",
        "*  Si usted eligió modalidad *Analista Senior*,  ya se las ingenierá SIN preguntar !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XWLelftXa7Zt",
      "metadata": {
        "id": "XWLelftXa7Zt",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "webfiles=\"https://storage.googleapis.com/open-courses/austral2025-af91/labo1r\"\n",
        "destino_local=\"/content/datasets\"\n",
        "destino_bucket=\"/content/buckets/b1/datasets\"\n",
        "\n",
        "\n",
        "archivo=\"dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $destino_bucket/$archivo; then\n",
        "  wget  $webfiles/$archivo  -O $destino_bucket/$archivo\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $destino_local/$pequeno; then\n",
        "  cp  $destino_bucket/$archivo  $destino_local/$archivo\n",
        "fi\n",
        "\n",
        "#-------\n",
        "\n",
        "archivo=\"gerencial_competencia_2025.csv.gz\"\n",
        "\n",
        "if ! test -f $destino_bucket/$archivo; then\n",
        "  wget  $webfiles/$archivo  -O $destino_bucket/$archivo\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $destino_local/$pequeno; then\n",
        "  cp  $destino_bucket/$archivo  $destino_local/$archivo\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oSKhZRToy2F7",
      "metadata": {
        "id": "oSKhZRToy2F7"
      },
      "source": [
        "## 8.3  Workflow Semillerio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85171302-a2d6-48cb-b9b2-8d839a276859",
      "metadata": {
        "id": "85171302-a2d6-48cb-b9b2-8d839a276859"
      },
      "source": [
        "## Inicializacion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eSU5vi00CPRS",
      "metadata": {
        "id": "eSU5vi00CPRS"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zq8dySimCPRT",
      "metadata": {
        "id": "Zq8dySimCPRT"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EL8wdHaUs59K",
      "metadata": {
        "id": "EL8wdHaUs59K",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1iE0U4_WCPRT",
      "metadata": {
        "id": "1iE0U4_WCPRT",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "atmIUEUNUrK5",
      "metadata": {
        "id": "atmIUEUNUrK5",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "require(\"data.table\")\n",
        "\n",
        "if( !require(\"R.utils\")) install.packages(\"R.utils\")\n",
        "require(\"R.utils\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BsxZ_ONyj9L_",
      "metadata": {
        "id": "BsxZ_ONyj9L_"
      },
      "source": [
        "#### Parametros\n",
        "Si es gerente, no cambie nada\n",
        "<br>Si es Analista, cambie el nombre del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Eqmof6d35Spn",
      "metadata": {
        "id": "Eqmof6d35Spn"
      },
      "source": [
        "### Usted DEBE ambiar \"PARAM experimento\" cada vez que desee correr un nuevo experimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "peRH7ySLCPRV",
      "metadata": {
        "id": "peRH7ySLCPRV",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM <- list()\n",
        "PARAM$semilla_primigenia <- 314159\n",
        "\n",
        "PARAM$experimento <- \"-clon\"\n",
        "PARAM$dataset <- \"analistasr_competencia_2025.csv.gz\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NoJbKo_4NG8A",
      "metadata": {
        "id": "NoJbKo_4NG8A"
      },
      "source": [
        "#### Carpeta del Experimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1gZD6ZMvCPRV",
      "metadata": {
        "id": "1gZD6ZMvCPRV",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# carpeta de trabajo\n",
        "\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"WF\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YVKBfLtkR8SO",
      "metadata": {
        "id": "YVKBfLtkR8SO"
      },
      "source": [
        "### 8.3.1   Preprocesamiento del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cr3K0RPVRjq6",
      "metadata": {
        "id": "cr3K0RPVRjq6"
      },
      "source": [
        "#### 8.3.1.1  DT incorporar dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xi0emX2ECPRV",
      "metadata": {
        "id": "Xi0emX2ECPRV",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(paste0(\"/content/buckets/b1/datasets/\", PARAM$dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MWuPzK3nSLY3",
      "metadata": {
        "id": "MWuPzK3nSLY3"
      },
      "source": [
        "#### 8.3.1.2  CA  Catastrophe Analysis\n",
        "Se intentan reparar las variables que para un mes están con todos los valores en cero."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UAI16-yCVcBS",
      "metadata": {
        "id": "UAI16-yCVcBS"
      },
      "source": [
        "El método que se utiliza es **Machine Learning** se asigna NA also valores, si ha leido bien, es la \"anti imputación de valores faltantes\"\n",
        "<br> Usted podrá aplicar aquí otros métodos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sTmliO_FXv9E",
      "metadata": {
        "id": "sTmliO_FXv9E",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "dataset[ foto_mes==202006, internet:=NA]\n",
        "dataset[ foto_mes==202006, mrentabilidad:=NA]\n",
        "dataset[ foto_mes==202006, mrentabilidad_annual:=NA]\n",
        "dataset[ foto_mes==202006, mcomisiones:=NA]\n",
        "dataset[ foto_mes==202006, mactivos_margen:=NA]\n",
        "dataset[ foto_mes==202006, mpasivos_margen:=NA]\n",
        "dataset[ foto_mes==202006, mcuentas_saldo:=NA]\n",
        "dataset[ foto_mes==202006, ctarjeta_visa_transacciones:=NA]\n",
        "dataset[ foto_mes==202006, mtarjeta_visa_consumo:=NA]\n",
        "dataset[ foto_mes==202006, mtarjeta_master_consumo:=NA]\n",
        "dataset[ foto_mes==202006, ccallcenter_transacciones:=NA]\n",
        "dataset[ foto_mes==202006, chomebanking_transacciones:=NA]\n",
        "dataset[ foto_mes==202006, chomebanking_transacciones:=NA]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-4NiANYFSYHG",
      "metadata": {
        "id": "-4NiANYFSYHG"
      },
      "source": [
        "#### 8.3.1.3  DR  Data Drifting\n",
        "Se intenta corregir el data drifting, quizas ajustando por IPC ...\n",
        "<br>Esta parte podrá ser abordada por todos los Analistas y también la Gerenciapero se decide pedagogicamente no incluirla en esta primer version para reducir la carga cognitiva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "L85A2lwKSe3k",
      "metadata": {
        "id": "L85A2lwKSe3k",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# sin codigo en esta primera version del workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7sppIDYeSn5X",
      "metadata": {
        "id": "7sppIDYeSn5X"
      },
      "source": [
        "#### 8.3.1.3  FE_intra_manual Feature Engineering intra-mes\n",
        "\n",
        "Agrego campos nuevos dentro del mismo mes, SIN considerar la historia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qrqf3j3_St3p",
      "metadata": {
        "id": "qrqf3j3_St3p",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# esta funcion atributos presentes existe debido a que las modalidades poseen datasets con distinta cantidad de campos\n",
        "atributos_presentes <- function( patributos )\n",
        "{\n",
        "  atributos <- unique( patributos )\n",
        "  comun <- intersect( atributos, colnames(dataset) )\n",
        "\n",
        "  return(  length( atributos ) == length( comun ) )\n",
        "}\n",
        "\n",
        "# el mes 1,2, ..12\n",
        "if( atributos_presentes( c(\"foto_mes\") ))\n",
        "  dataset[, kmes := foto_mes %% 100]\n",
        "\n",
        "# variable extraida de una tesis de maestria de Irlanda\n",
        "if( atributos_presentes( c(\"mpayroll\", \"cliente_edad\") ))\n",
        "  dataset[, mpayroll_sobre_edad := mpayroll / cliente_edad]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iC4viwOdY5Kp",
      "metadata": {
        "id": "iC4viwOdY5Kp",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# visualizo las columas del dataset a esta etapa\n",
        "colnames(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9682b4ca-3ab3-4bbc-a36a-b185361e6b6b",
      "metadata": {
        "id": "9682b4ca-3ab3-4bbc-a36a-b185361e6b6b"
      },
      "source": [
        "#### 8.3.1.4  FE_rf Feature Engineering de nuevas variables a partir de hojas de Random Forest\n",
        "\n",
        "Esto se mostrará unicamente a la *modalidad Analista Sr*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ljA3h0jOcciP",
      "metadata": {
        "id": "ljA3h0jOcciP",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# No se implementa Feature Engineering a partir de Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XaRBjQj8ZRUZ",
      "metadata": {
        "id": "XaRBjQj8ZRUZ"
      },
      "source": [
        "#### 8.3.1.5  FEhist Feature Engineering historico\n",
        "\n",
        "El Fature Engineering Histórico es la etapa que más aporta a la ganancia final, ya que enriquece cada registro del dataset con su historia."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfe3b8cf-0707-4512-92e7-c1407bb3f73b",
      "metadata": {
        "id": "cfe3b8cf-0707-4512-92e7-c1407bb3f73b"
      },
      "source": [
        "Para cada campo del dataset original (*)\n",
        "se crean lo siguientes campos de a partir de la historia\n",
        "* lag1  lags de orden 1\n",
        "* delta1  =  valor actual - lag1\n",
        "* lag2  lags de orden 2\n",
        "* delta2  = valor actual - lag2\n",
        "\n",
        "\n",
        "(*) Excepto para los campos  <numero_de_cliente,  foto_mes,  clase_ternaria>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7850b948-827d-4a2a-b4d3-a5e459b47c11",
      "metadata": {
        "id": "7850b948-827d-4a2a-b4d3-a5e459b47c11",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Feature Engineering Historico\n",
        "# ordeno el dataset\n",
        "setorder(dataset, numero_de_cliente, foto_mes)\n",
        "\n",
        "# todo es lagueable, menos la primary key y la clase\n",
        "cols_lagueables <- copy( setdiff(\n",
        "    colnames(dataset),\n",
        "    c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
        ") )\n",
        "\n",
        "# https://rdrr.io/cran/data.table/man/shift.html\n",
        "\n",
        "# lags de orden 1\n",
        "dataset[,\n",
        "    paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
        "    by = numero_de_cliente,\n",
        "    .SDcols = cols_lagueables\n",
        "]\n",
        "\n",
        "# lags de orden 2\n",
        "dataset[,\n",
        "    paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
        "    by = numero_de_cliente,\n",
        "    .SDcols = cols_lagueables\n",
        "]\n",
        "\n",
        "# agrego los delta lags\n",
        "for (vcol in cols_lagueables)\n",
        "{\n",
        "    dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
        "    dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cea690d9-ece9-4852-a5e2-f337c31b6721",
      "metadata": {
        "id": "cea690d9-ece9-4852-a5e2-f337c31b6721"
      },
      "source": [
        "Verificacion de los campos recien creados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f772896b-595a-47d4-8905-c15304ac9452",
      "metadata": {
        "id": "f772896b-595a-47d4-8905-c15304ac9452",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "ncol(dataset)\n",
        "colnames(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l8mKij0XaDY0",
      "metadata": {
        "id": "l8mKij0XaDY0"
      },
      "source": [
        "#### 8.3.1.6  FEhist Reduccion dimensionalidad con canaritos\n",
        "\n",
        "Esta etapa solo se mostrará a la *modalidad Anlista Sr* por algun canal secreto de forma de no confundir a los *Analista Jr*  nni distraer con detalles operativos a la estratégica *Modalidad Gerencial*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QrmnPtlBcEgx",
      "metadata": {
        "id": "QrmnPtlBcEgx",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# No se implementa la reduccion de la dimensionalidad con canaritos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fccd1d8",
      "metadata": {},
      "source": [
        "## Algoritmo Genético"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f26b4df",
      "metadata": {},
      "source": [
        "### Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df9ead95",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# paquetes necesarios para la Bayesian Optimization\n",
        "if(!require(\"DiceKriging\")) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if(!require(\"mlrMBO\")) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")\n",
        "\n",
        "if(!require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
        "        require(\"lightgbm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cfa7703",
      "metadata": {},
      "source": [
        "### Selección de variables de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95c0e4b0",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "#Defino los campos\n",
        "\n",
        "campos <- colnames(dataset)\n",
        "campos_monetarios <- campos[campos %like%\n",
        "  \"^(m|Visa_m|Master_m|vm_m)\"]\n",
        "campos_cant <- campos[campos %like% \"^c\" & campos != \"cliente_vip\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db9f8479",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Defino pool inicial de variables\n",
        "\n",
        "if (!file.exists(\"var_pool.txt\")){\n",
        "  var_pool <- data.table(\n",
        "    Feature = cols_lagueables, #Variable\n",
        "    from1 = NA, #variables 1 usada en iteración anterior\n",
        "    from2 = NA, #variables 2 usada en iteración anterior\n",
        "    op = NA, #operación usada para obtenerla\n",
        "    complete_form = cols_lagueables #forma completa (para uso final)\n",
        "  )\n",
        "\n",
        "  var_pool[, clase := fifelse(Feature %in% campos_monetarios, \"m\",\n",
        "                      fifelse(Feature %in% campos_cant, \"c\", \"b\"))]\n",
        "} else {\n",
        "  var_pool <- fread(\"var_pool.txt\")\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5a43c0f",
      "metadata": {},
      "source": [
        "### Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b73b9f3d",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "meses <- data.frame(dataset$foto_mes)\n",
        "meses_unique <- as.list(sapply(meses, unique))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27bebee8",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM$trainingstrategy$validate <- c(202105, 202104)\n",
        "\n",
        "PARAM$trainingstrategy$training <- c(\n",
        "  202102, 202101,\n",
        "  202012, 202011, 202010, 202009, 202008, 202007,\n",
        "  202006, 202005, 202004, 202003\n",
        ")\n",
        "\n",
        "PARAM$trainingstrategy$training_pct <- 0.1\n",
        "\n",
        "\n",
        "PARAM$trainingstrategy$positivos <- c( \"BAJA+1\", \"BAJA+2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8bd23e7",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM$hipeparametertuning$num_interations <- 50\n",
        "\n",
        "# parametros fijos del LightGBM\n",
        "PARAM$lgbm$param_fijos <- list(\n",
        "  objective= \"binary\",\n",
        "  metric= \"auc\",\n",
        "  first_metric_only= TRUE,\n",
        "  boost_from_average= TRUE,\n",
        "  feature_pre_filter= FALSE,\n",
        "  verbosity= -100,\n",
        "  force_row_wise= TRUE, # para evitar warning\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "  extra_trees = FALSE,\n",
        "\n",
        "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
        "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
        "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
        "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
        "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
        "\n",
        "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
        "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
        "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  is_unbalance = FALSE, #\n",
        "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
        "\n",
        "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  max_drop = 50, # <=0 means no limit\n",
        "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
        "\n",
        "  max_bin= 31,\n",
        "  num_iterations= 2048,  # valor grande, lo limita early_stopping_rounds\n",
        "  early_stopping_rounds= 200\n",
        ")\n",
        "\n",
        "\n",
        "PARAM$hipeparametertuning$hs <- makeParamSet(\n",
        "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
        "  makeNumericParam(\"feature_fraction\", lower = 0.05, upper = 0.90),\n",
        "  makeNumericParam(\"coverage\", lower = 0.05, upper = 1.0), # nuevo\n",
        "  makeNumericParam(\"leaf_size\", lower = 0.001, upper = 0.2) # nuevo\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b97054ea",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM$trainingstrategy$final_train <- c( 202105, 202104, 202103, 202102, 202101,\n",
        "  202012, 202011, 202010, 202009, 202008, 202007, 202006, 202005, 202004, 202003\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad8b290d",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# seteo la clase01   1={BAJA+1, BAJA+2}   0={CONTINUA}\n",
        "dataset[, clase01 := ifelse( clase_ternaria %in% PARAM$trainingstrategy$positivos, 1, 0 )]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c00714b3",
      "metadata": {},
      "source": [
        "### Funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7da4ba4",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# En  x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en validate del modelo entrenado\n",
        "#  en el parametro x llegan los hiperparámetros que se estan optimizando\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"))\n",
        "\n",
        "  # uno la lista de hiperparametros : fijos + variables\n",
        "  param_completo <- c(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelo_train <- lgb.train(\n",
        "    data= dtrain,\n",
        "    valids= list(valid = dvalidate),\n",
        "    eval= \"auc\",\n",
        "    param= param_completo,\n",
        "    verbose= -100\n",
        "  )\n",
        "\n",
        "  # recupero la AUC en validation\n",
        "  AUC <- modelo_train$record_evals$valid$auc$eval[[modelo_train$best_iter]]\n",
        "\n",
        "  # esta es la forma de devolver un parametro extra\n",
        "  attr(AUC, \"extras\") <- list(\"num_iterations\"= modelo_train$best_iter)\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelo_train)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  return(AUC)\n",
        "}\n",
        "\n",
        "get_combinations <- function(cols, n, seed) {\n",
        "  set.seed(seed)\n",
        "  combinations <- t(combn(cols, 2))\n",
        "  if (nrow(combinations) > n) {\n",
        "    return(combinations[sample(nrow(combinations), n), ])\n",
        "  } else {\n",
        "    return(combinations)\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "720b36ca",
      "metadata": {},
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd89378",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "safe_ops <- list(\n",
        "  `*`    = function(a, b) a * b,\n",
        "  `/`    = function(a, b) a / b\n",
        ")\n",
        "\n",
        "all_ops <- list(\n",
        "  `+`    = function(a, b) a + b,\n",
        "  `-`    = function(a, b) a - b,\n",
        "  `*`    = function(a, b) a * b,\n",
        "  `/`    = function(a, b) a / b\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33cf6b20",
      "metadata": {},
      "source": [
        "### Algoritmo Genético"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548e3fcc",
      "metadata": {},
      "source": [
        "Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b636ece",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Numero de generaciones\n",
        "n_generations <- 25\n",
        "\n",
        "# Numero de mutaciones a realizar\n",
        "n_mutations <- 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a92f80a4",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "102e1a22",
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Loop principal\n",
        "\n",
        "# guardo dataset original en otra variable\n",
        "dataset_original <- copy(dataset)\n",
        "\n",
        "for (generation in 1:n_generations) {\n",
        "\n",
        "    if(exists(\"dataset\")){rm(dataset)} #por las dudas\n",
        "    dataset <- copy(dataset_original) #(para no tener que ir dropeando variables que se van, ver si es bueno para la memoria)\n",
        "\n",
        "    impo_name <- paste0(\"impo_\",generation,\".txt\")\n",
        "    seed_loop <- PARAM$semilla_primigenia + generation - 1 #por ahora generamos las seed sumando de a una\n",
        "    #check generacion completa\n",
        "    if (file.exists(impo_name)){ \n",
        "        next #si existe el impo de esta generación quiere decir que ya se procesó todo\n",
        "    }\n",
        "\n",
        "    #cargo var_pool\n",
        "    cols_to_mutate <- var_pool[,Feature]\n",
        "\n",
        "    #si no hay alguna variable la creo\n",
        "    for (var in cols_to_mutate){\n",
        "                # Checkeo si existe en el dataset\n",
        "                if(!(var %in% colnames(dataset)))\n",
        "                    {\n",
        "                    dataset <- dataset[, (var) := get(complete_form)]  #creo que esto no anda aun, tengo que traerme la var\n",
        "                    }\n",
        "            }\n",
        "\n",
        "    # deletear cosas que no sirven para no saturar la memoria\n",
        "    if(exists(\"dtrain\")){rm(dtrain)}\n",
        "    if(exists(\"dvalidate\")){rm(dvalidate)}\n",
        "    if(exists(\"dfinal_train\")){rm(dfinal_train)}\n",
        "    if(exists(\"tb_importancia\")){rm(tb_importancia)}    \n",
        "\n",
        "    # crear variables nuevas\n",
        "        # combinaciones\n",
        "        # mutaciones\n",
        "        # guaradar provisoriamente las variables nuevas (solo guardamos en var_pool las que realmente nos van a servir)\n",
        "\n",
        "    combinations <- get_combinations(cols_to_mutate, n_mutations, seed_loop)\n",
        "\n",
        "    new_vars <- data.table(\n",
        "                    Feature = character(),\n",
        "                    from1 = character(),\n",
        "                    from2 = character(),\n",
        "                    op = character(),\n",
        "                    complete_form = character(),\n",
        "                    clase = character()\n",
        "                )\n",
        "\n",
        "    for (var_num in 1:n_mutations){\n",
        "        var_name <- paste0(\"gen_\",generation,\"_n_\",var_num)\n",
        "        var1 <- combinations[var_num, 1]\n",
        "        var2 <- combinations[var_num, 2]\n",
        "        clase1 <- var_pool[Feature == var1, clase][[1]]\n",
        "        clase2 <- var_pool[Feature == var2, clase][[1]]\n",
        "        if (!is.na(clase1) && !is.na(clase2) &&\n",
        "            ((clase1 == \"m\" && clase2 == \"m\") ||\n",
        "            (clase1 == \"c\" && clase2 == \"c\") ||\n",
        "            (clase1 == \"b\" && clase2 == \"b\"))) {\n",
        "            safe <- FALSE\n",
        "            clase_op <- clase1\n",
        "        } else {\n",
        "            safe <- TRUE\n",
        "            clase_op <- NA\n",
        "        }\n",
        "\n",
        "        # elijo una operación\n",
        "        inline_seed <- seed_loop*var_num\n",
        "        set.seed(inline_seed)\n",
        "        operation_name <- ifelse(safe == TRUE, sample(names(safe_ops), 1), sample(names(all_ops), 1))\n",
        "        operation <- all_ops[[operation_name]] #como acá estan todas por ahora puedo esar siempre este\n",
        "\n",
        "        # realizo la mutación\n",
        "        dataset <- dataset[, (var_name) := operation(get(var1),get(var2))]\n",
        "        complete_form_1 = var_pool[Feature == var1, complete_form][[1]]\n",
        "        complete_form_2 = var_pool[Feature == var2, complete_form][[1]]\n",
        "        new_var <- data.table(\n",
        "        Feature = var_name,\n",
        "        from1 = combinations[var_num,1],\n",
        "        from2 = combinations[var_num,2],\n",
        "        op = operation_name,\n",
        "        complete_form = paste0(\"(\",complete_form_1,operation_name,complete_form_2,\")\"),\n",
        "        clase = clase_op\n",
        "        )\n",
        "\n",
        "        # la agrego a las variables recien creadas para analizar luego\n",
        "        new_vars <- rbind(new_vars, new_var)\n",
        "    }\n",
        "\n",
        "    ######## bayesiana\n",
        "\n",
        "    # los campos en los que se entrena\n",
        "    campos_buenos <- copy( setdiff(\n",
        "        colnames(dataset), c(\"clase_ternaria\",\"clase01\",\"azar\")))\n",
        "\n",
        "    # preparo para que se puede hacer undersampling de los CONTINUA\n",
        "    #  solamente por un tema de VELOCIDAD\n",
        "    set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "    dataset[, azar:=runif(nrow(dataset))]\n",
        "\n",
        "    # undersampling de los CONTINUA\n",
        "    dataset[, fold_train :=  foto_mes %in%  PARAM$trainingstrategy$training &\n",
        "        (clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\") |\n",
        "        azar < PARAM$trainingstrategy$training_pct ) ]\n",
        "\n",
        "    dtrain <- lgb.Dataset(\n",
        "        data= data.matrix(dataset[fold_train == TRUE, campos_buenos, with = FALSE]),\n",
        "        label= dataset[fold_train == TRUE, clase01],\n",
        "        free_raw_data= TRUE\n",
        "        )\n",
        "\n",
        "    # datos de validation\n",
        "    dvalidate <- lgb.Dataset(\n",
        "    data= data.matrix(dataset[foto_mes %in% PARAM$trainingstrategy$validate, campos_buenos, with = FALSE]),\n",
        "    label= dataset[foto_mes %in% PARAM$trainingstrategy$validate, clase01],\n",
        "    free_raw_data= TRUE\n",
        "    )\n",
        "\n",
        "\n",
        "    # Esto podría sacarlo pero por ahora lo dejo por el ctrl\n",
        "    configureMlr(show.learner.output = FALSE)\n",
        "\n",
        "    # configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "    # por favor, no desesperarse por lo complejo\n",
        "    obj.fun <- makeSingleObjectiveFunction(\n",
        "        fn= EstimarGanancia_AUC_lightgbm, # la funcion que voy a maximizar\n",
        "        minimize= FALSE, # estoy Maximizando AUC\n",
        "        noisy= FALSE,\n",
        "        par.set= PARAM$hipeparametertuning$hs,\n",
        "        has.simple.signature= FALSE # paso los parametros en una lista\n",
        "    )\n",
        "\n",
        "    # cada 600 segundos guardo el resultado intermedio\n",
        "    save_path <- paste0(\"HT_\",generation,\".RDATA\")\n",
        "    ctrl <- makeMBOControl(\n",
        "        save.on.disk.at.time= 600,\n",
        "        save.file.path= save_path\n",
        "    )\n",
        "\n",
        "    # indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "    ctrl <- setMBOControlTermination(\n",
        "        ctrl,\n",
        "        iters= PARAM$hipeparametertuning$num_interations  # cantidad de iteraciones inteligentes\n",
        "    )\n",
        "\n",
        "    # defino el método estandar para la creacion de los puntos iniciales\n",
        "    #   los \"No Inteligentes\"\n",
        "    ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
        "\n",
        "    # mas configuraciones\n",
        "    surr.km <- makeLearner(\n",
        "        \"regr.km\",\n",
        "        predict.type= \"se\",\n",
        "        covtype= \"matern3_2\",\n",
        "        control= list(trace = TRUE)\n",
        "    )\n",
        "\n",
        "    # inicio la optimizacion bayesiana\n",
        "\n",
        "    if (!file.exists(save_path)) {\n",
        "    bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "    } else {\n",
        "    bayesiana_salida <- mboContinue(save_path) # retomo en caso que ya exista\n",
        "    }\n",
        "\n",
        "    # almaceno los resultados de la Bayesian Optimization\n",
        "    # y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "    tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "    # ordeno en forma descendente por AUC = y\n",
        "    setorder(tb_bayesiana, -y, -num_iterations)\n",
        "\n",
        "    # grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "    file_path <- paste0(\"BO_\",generation,\"_log.txt\")\n",
        "    fwrite( tb_bayesiana,\n",
        "    file=file_path,\n",
        "    sep=\"\\t\"\n",
        "    )\n",
        "\n",
        "    # los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "    PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "    1, # el primero es el de mejor AUC\n",
        "    list(learning_rate, feature_fraction, coverage, leaf_size)\n",
        "    ]\n",
        "\n",
        "    print(PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "    ######## final train\n",
        "\n",
        "    dataset[, fold_final_train := foto_mes %in% PARAM$trainingstrategy$final_train ]\n",
        "\n",
        "    # creo el dfinal_train en formato  LightGBM\n",
        "    dfinal_train <- lgb.Dataset(\n",
        "    data= data.matrix(dataset[fold_final_train == TRUE, campos_buenos, with= FALSE]),\n",
        "    label= dataset[fold_final_train == TRUE, clase01],\n",
        "    free_raw_data= TRUE\n",
        "    )\n",
        "\n",
        "    nrow( dfinal_train) # verifico el tamaño\n",
        "\n",
        "\n",
        "    # uno los parametros fijos y los mejores encontrados de los variables\n",
        "    fijos <- copy(PARAM$lgbm$param_fijos)\n",
        "\n",
        "    # quito lo que optimice en la Bayesian Optimization\n",
        "    fijos$num_iterations <- NULL\n",
        "    fijos$early_stopping_rounds <- NULL\n",
        "\n",
        "    # agrego a los hiperparametros fijos los que encontre con la Bayesian Optimization\n",
        "    param_final <- c(fijos, PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "    # hago la transformacion de leaf_size y  coverage\n",
        "    if( \"leaf_size\"  %in% names(param_final) &\n",
        "        \"coverage\"  %in% names(param_final)\n",
        "    )\n",
        "    {\n",
        "        # primero defino el tamaño de las hojas\n",
        "        param_final$min_data_in_leaf <- pmax( 1,  round( nrow(dtrain) * param_final$leaf_size )  )\n",
        "        # luego la cantidad de hojas en funcion del valor anterior, el coverage, y la cantidad de registros\n",
        "        param_final$num_leaves <- pmin( 131072,\n",
        "        pmax( 8,  round( ( param_final$coverage * nrow( dtrain ) / param_final$min_data_in_leaf ) ) ))\n",
        "    }\n",
        "\n",
        "    if( \"leaf_size\"  %in% names(param_final) &\n",
        "        !( \"coverage\"  %in% names(param_final) )\n",
        "    )\n",
        "    {\n",
        "        # primero defino el tamaño de las hojas\n",
        "        param_final$min_data_in_leaf <- pmax( 1,  round( nrow(dtrain) * param_final$leaf_size )  )\n",
        "    }\n",
        "                        \n",
        "    final_model <- lgb.train(\n",
        "    data= dfinal_train,\n",
        "    param= param_final,\n",
        "    verbose= -100\n",
        "    )\n",
        "\n",
        "    modelo_path <- paste0(\"modelo_\",generation,\".txt\")\n",
        "    lgb.save(final_model, modelo_path)\n",
        "\n",
        "\n",
        "    # ahora imprimo la importancia de variables\n",
        "\n",
        "    tb_importancia <- as.data.table(lgb.importance(final_model))\n",
        "    archivo_importancia <- impo_name\n",
        "\n",
        "    fwrite( tb_importancia,\n",
        "    file= archivo_importancia,\n",
        "    sep= \"\\t\"\n",
        "    )\n",
        "\n",
        "    #### comparación de las variables con sus padres\n",
        "    tb_importancia[, rank := .I]\n",
        "    \n",
        "\n",
        "    for (i in 1:nrow(new_vars)){\n",
        "        fila <- new_vars[i]\n",
        "\n",
        "        var_rank <- tb_importancia[Feature == fila$Feature, if (.N == 0) NA else rank[[1]]]\n",
        "        from1_rank <- tb_importancia[Feature == fila$from1, if (.N == 0) NA else rank[[1]]]\n",
        "        from2_rank <- tb_importancia[Feature == fila$from2, if (.N == 0) NA else rank[[1]]]\n",
        "\n",
        "        if (length(var_rank) == 0) var_rank <- NA\n",
        "        if (length(from1_rank) == 0) from1_rank <- NA\n",
        "        if (length(from2_rank) == 0) from2_rank <- NA\n",
        "\n",
        "        if (is.na(var_rank)){\n",
        "            next\n",
        "        }\n",
        "\n",
        "        if (is.na(from1_rank) & is.na(from2_rank)){ #significa que es mas significativo var_rank porque no es na\n",
        "            var_pool <- rbind(var_pool, fila)\n",
        "        }\n",
        "\n",
        "        if (!is.na(var_rank) && !is.na(from1_rank) && !is.na(from2_rank)) {\n",
        "            if ((var_rank < from1_rank) & (var_rank < from2_rank)) {\n",
        "                var_pool <- rbind(var_pool, fila)\n",
        "            }\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "    fwrite( new_vars,\n",
        "        file= \"new_vars.txt\",\n",
        "        sep= \"\\t\"\n",
        "        )\n",
        "\n",
        "    fwrite(var_pool,\n",
        "           file = \"var_pool.txt\",\n",
        "           sep = \"\\t\"\n",
        "          )\n",
        "    \n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b615a62-20cc-4e95-9af2-6b6db38d5efb",
      "metadata": {
        "id": "1b615a62-20cc-4e95-9af2-6b6db38d5efb",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
